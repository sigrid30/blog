<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Intro to Probability Theory" /><meta property="og:locale" content="en" /><meta name="description" content="Probability theory has started to develop since 17 century as a tool to analyze gambling games. It allows to model a random experience whose outcome can not be predicted with certainty. Today it has a wide applications in prediction, risk assessment and modeling. This post is going to be a basic overview of some important aspects in probability theory." /><meta property="og:description" content="Probability theory has started to develop since 17 century as a tool to analyze gambling games. It allows to model a random experience whose outcome can not be predicted with certainty. Today it has a wide applications in prediction, risk assessment and modeling. This post is going to be a basic overview of some important aspects in probability theory." /><link rel="canonical" href="https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/" /><meta property="og:url" content="https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/" /><meta property="og:site_name" content="Asif Mammadov" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-10-12T18:40:10+04:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Intro to Probability Theory" /><meta name="twitter:site" content="@asif_mammad" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"Probability theory has started to develop since 17 century as a tool to analyze gambling games. It allows to model a random experience whose outcome can not be predicted with certainty. Today it has a wide applications in prediction, risk assessment and modeling. This post is going to be a basic overview of some important aspects in probability theory.","url":"https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/","@type":"BlogPosting","headline":"Intro to Probability Theory","dateModified":"2022-01-19T23:51:05+04:00","datePublished":"2021-10-12T18:40:10+04:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/"},"@context":"https://schema.org"}</script><title>Intro to Probability Theory | Asif Mammadov</title><link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/blog/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/blog/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Asif Mammadov"><meta name="application-name" content="Asif Mammadov"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/blog/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/blog/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="https://sigrid30.github.io" alt="avatar" class="mx-auto"> <img src="/blog/assets/img/profile.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/blog/">Asif Mammadov</a></div><div class="site-subtitle font-italic">Senior Computer Science student</div></div><ul class="w-100"><li class="nav-item"> <a href="/blog/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/blog/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/blog/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/blog/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/blog/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/asif-mammadov" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://www.linkedin.com/in/asif-mammadov/" aria-label="linkedin" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://twitter.com/asif_mammad" aria-label="twitter" class="order-5" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['asif.mammad','hotmail.com'].join('@')" aria-label="email" class="order-6" > <i class="fas fa-envelope"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/blog/"> Home </a> </span> <span>Intro to Probability Theory</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Intro to Probability Theory</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Asif Mammadov </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Oct 12, 2021, 6:40 PM +0400" >Oct 12, 2021<i class="unloaded">2021-10-12T18:40:10+04:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Wed, Jan 19, 2022, 11:51 PM +0400" >Jan 19<i class="unloaded">2022-01-19T23:51:05+04:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1476 words">8 min read</span></div></div><div class="post-content"><p>Probability theory has started to develop since 17 century as a tool to analyze gambling games. It allows to model a random experience whose outcome can not be predicted with certainty. Today it has a wide applications in prediction, risk assessment and modeling. This post is going to be a basic overview of some important aspects in probability theory.</p><h2 id="probabilistic-model">Probabilistic model</h2><h3 id="definition">Definition</h3><p>To put in naive definition, probability function $P$ of a certain event is a number of <strong>favorable</strong> outcomes to <strong>all</strong> the possible outcomes. The range of probability function is between 0 and 1. The total number of outcomes is often noted as $\Omega$ (called <code class="language-plaintext highlighter-rouge">certain event</code>) and $P(\Omega)=1$. So the general formula is given by:</p>\[P(A) = \dfrac{card(A)}{card(\Omega)}\]<p>Followed from set theory, to find the probability of event A or event B to occur we use:</p>\[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]<p>It is important to metion about two particular relations between the events.</p><ol><li><p>Compatibility</p><p>The events are said <strong>incompatible</strong> if they cannot occur at the same time. For example, a bag contains red and green balls. When choosing the ball it can be either red or green, not both at the same time. So event of ball being red and event of ball being red are incompatible.</p>\[P(A \cap B) = \emptyset\]<li><p>Dependence</p><p>The events are called <strong>independent</strong> when they do not depend on each other. For example, rolling a dice and tossing a coin are independent events as the outcomes of one of them does not affect to other event. On the other hand, buying a soda after having a lunch may have different probability that buying a soda without having lunch.</p>\[P(A \cap B) = P(A)P(B)\]</ol><h3 id="conditional-probability">Conditional Probability</h3><p>When the event B happens under condition of A we get:</p>\[P(B | A) = \dfrac{P(A \cap B)}{P(A)}\]<h3 id="total-probability-law">Total Probability law</h3>\[P(B) = P(B | A)P(A) + P(B | A^{c})P(A^{c})\]<h3 id="bayes-formula">Bayes formula</h3>\[P(A|B) = \dfrac{P(B|A)P(B)}{P(B | A)P(A) + P(B | A^{c})P(A^{c}) }\]<h2 id="discrete-random-variables">Discrete Random Variables</h2><h3 id="definition-1">Definition</h3><p>A <strong>random variable</strong>, often denoted as $X$, is a variable that defines as a numerical value possible outcomes of a random event. Random variables can be discrete (finite) and continuous (infinite).</p><p>For example, we draw successfully 3 balls from a bag containing red, green and blue balls. We let random variable $X$ to correspond to the number of times a green ball appears in the result. Let us draw the table with possible events $\omega$, random variable $X$, and the number of events for each value of a random variable:</p><div class="table-wrapper"><table><thead><tr><th style="text-align: center">$x$<th style="text-align: center">0<th style="text-align: center">1<th style="text-align: center">2<th style="text-align: center">3<tbody><tr><td style="text-align: center">$w$<td style="text-align: center">RRR RRB RBR <br />RBB BRR BRB <br />BBR BBB<td style="text-align: center">RRG RGR RGB <br />RBG GRR GRB <br />GBR GBB BRG <br />BGR BGB BBG<td style="text-align: center">RGG GRG GGR <br />GGB GBG BGG<td style="text-align: center">GGG<tr><td style="text-align: center"># of events<td style="text-align: center">8<td style="text-align: center">12<td style="text-align: center">6<td style="text-align: center">1<tr><td style="text-align: center">$P[X_{i}=x]$<td style="text-align: center">$\dfrac{8}{27}$<td style="text-align: center">$\dfrac{12}{27}$<td style="text-align: center">$\dfrac{6}{27}$<td style="text-align: center">$\dfrac{1}{27}$</table></div><p>To analyze the distribution of variables we often need some metrics.</p><p>The expected value, also called expectation or mean, is used to calculate the average outcome of the distribution and we define it as :</p>\[E[X] = \sum_k kP[X=k]\]<p>where k is numerical value of X.</p><p>The <strong>variance</strong> defines how much the distribution is spread out, we define it as:</p>\[Var[X] = E[(X - E[X])^2] = \sum_k (k - E[X])^2 = E[X^2] - E[X]^2\]<p>The <strong>standard deviation</strong> is given by : \(\sigma_x = \sqrt{Var[X]}\)</p><p>Covariance and correlation are used to understand the relationship between two variables.</p><p>We define covariance as :</p>\[Cov(X, Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]\]<p>Correlation is a standardized form of covariance and is defined as :</p>\[Cor(X, Y) = \dfrac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}}\]<h3 id="bernoulli-trial">Bernoulli Trial</h3><p>It is a random experiment which has exactly two possible outcomes : <em>success</em> and <em>failure</em>. We associate a random variable $X$ which takes two values, 1 in case of success, and 0 in case of failure.</p>\[P[X=1] = p\] \[P[X=0] = q = 1 - p\]<h3 id="bernoulli-distribution">Bernoulli Distribution</h3><p>Bernoulli process consists in the repetition of the same Bernoulli trial $n$ times under the same conditions.</p><p>We let X be a random variable referring to the number of obtained success during Bernoulli process of $n$ trials. Then $X$ follows a <strong>Bernoulli distribution</strong> of parameters $(n, p)$, denoted $B(n, p)$.</p>\[P[X=k] = \binom{n}{r}p^k(1-p)^{n-k}\] \[E[X] = np\] \[Var[X] = np(1-p)\]<p>It can be used in solving questions with replacement.</p><h3 id="hypergeometric-distribution">Hypergeometric Distribution</h3><p>The hypergeometric distribution describes the probability of $k$ successes (with specific feature) in $n$ draws ($k \leq $n), without replacement from a population of size $N$ containing $K$ objects with the specific feature. It is denoted as $K(N, K, n)$.</p>\[P[X=k] = \dfrac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}\] \[E[X] = n \dfrac{K}{N}\] \[Var(X) = n \dfrac{K}{N} \dfrac{N-K}{N} \dfrac{N-n}{N-1}\]<h3 id="geometric-distribution">Geometric Distribution</h3><p>A geometric distribution corresponds to the number of times a random experiment has to be repeated until having the first success. It is a Bernoulli process where the nubmber of successes is 1 and the number of trials $X$ is random. It is denoted as $G(p)$.</p>\[\forall k = 1,2,..., P[X=k] = p(1-p)^{k-1}\] \[E[X] = \dfrac{1}{p}\] \[Var[X] = \dfrac{1-p}{p^2}\]<p>where $p$ is the proability of successes.</p><h3 id="poisson-distribution">Poisson Distribution</h3><p>It can be used as an approximation to the Binomial distribution when $np \le 10$ and $n \ge 50$. We say that a random variable $X$ follows the Posson distribution of parameter $\lambda$ if</p>\[\forall k \in \mathbb{N}, P[X=k] = \dfrac{\lambda^k}{k!}e^{-\lambda}\]<p>And,</p>\[E[X] = Var[X] = \lambda\]<h3 id="uniform-distribution">Uniform Distribution</h3><p>We say that a random variable $X$ takes $n$ possible values $k_1, k_2,…, k_n$ follows a uniform distribution if</p>\[\forall i = 1,...,n, P[X=k_i] = \dfrac{1}{n}\]<p>And,</p>\[E[X] = \dfrac{n+1}{2}\] \[Var[X] = \dfrac{n^2-1}{12}\]<h2 id="continuous-random-variables">Continuous Random Variables</h2><h3 id="definition-2">Definition</h3><p>A continuous random variable can take infinitely many values. For example: measuring time, distance, temperature, etc.</p><p>We say that $f$ is a <strong>probability density function</strong> (p.d.f.) of the continuous random variable $X$ if</p>\[\forall x \in \mathbb{R} f(x) \ge 0 \space \text{and} \int_{\mathbb{R}} f(x) \, dx = 1\]<p>The probability of a continuous random variable $X$ is defined by meas of the p.d.f. as:</p>\[\forall a, b \in \mathbb{R}, P[a \le X \le b] = \int_a^b f(x) \, dx\]<p>For a continuous random variable $X$, the function $F$ defined as:</p>\[\forall x \in \mathbb{R}, F(x) = P[X \le x] = P[X &lt; x] = \int_{-\infty}^x f(t) \, dt\]<p>is called the <strong>cumulative distribution function</strong> of $X$.</p><p>We have,</p>\[P[a \le X \le b] = P[a &lt; X &lt; b] = F(b) - F(a)\]<p>The <strong>expectation</strong> of $X$ is defined as:</p>\[E[X] = \int_{-\infty}^{+\infty} xf(x) \, dx\]<p>And the <strong>variance</strong> of $X$ is:</p>\[Var[X] = E[X^2] - E[X]^2\]<h3 id="normal-distribution">Normal Distribution</h3><h5 id="standard-normal-function">Standard Normal function</h5><p>We say that continuous random variable $X$ follows the standard normal distribution, denoted $N(0, 1)$, if its p.d.f. $f$ is given by:</p>\[f(x) = \dfrac{1}{\sqrt{2\pi}}exp(-\dfrac{x^2}{2}), \forall x \in \mathbb{R}\] \[P[a \le X \le b] = \dfrac{1}{\sqrt{2\pi}} \int_a^b exp(-\dfrac{x^2}{2}) \, dx = \phi(b) - \phi(a)\]<p>where $\phi$ is the cumulative distribution function of $X$ which corresponds to the primitive of $f$. We usually do not compute it ourselves but have the table with prepared values.</p>\[E[X] = \mu = 0 \text{ and } Var[X] = \sigma = 1\]<p><img data-proofer-ignore data-src="https://miro.medium.com/max/1838/1*IdGgdrY_n_9_YfkaCh-dag.png" alt="Normal-Distribution-img" /> <em>Bell curve <a href="#references">[1]</a></em></p><h5 id="general-normal-function">General normal function</h5><p>More general form of the normal distribution is given by:</p>\[f(x) = \dfrac{1}{\sqrt{2\pi}\sigma} exp(- \dfrac{(x-\mu)^2}{2\sigma^2}), \forall x \in \mathbb{R}\]<p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/1200px-Normal_Distribution_PDF.svg.png" alt="General-Normal-Distribution-img" width="500" /> <em>General Normal Distribution <a href="#references">[2]</a></em></p>\[E[X] = \mu \text{ and } Var[X] = \sigma\]<p>If continuous random variable $X$ follows the normal p.d.f. $N(\mu, \sigma)$, then continuous random variable $Z = \dfrac{X-\mu}{\sigma}$ follows the standard normal p.d.f. $N(0, 1)$.</p><h3 id="exponential-distribution">Exponential Distribution</h3><p>We say that continuous random variable $X$ follows an exponential distribution for $\lambda &gt; 0$, denoted $\mathcal{E}(\lambda)$, if its p.d.f. is given by:</p>\[f(x) = \begin{cases} 0, &amp; \text{if } x &lt; 0 \\[2ex] \lambda exp(-\lambda x), &amp; \text{if } x \ge 0 \end{cases}\] \[E[X] = \dfrac{1}{\lambda}\] \[Var[X] = \dfrac{1}{\lambda^2}\]<p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Exponential_probability_density.svg/1200px-Exponential_probability_density.svg.png" alt="Exponential-Distribution-img" width="500" /> <em>Exponential Distribution <a href="#references">[3]</a></em></p><h3 id="continuous-uniform-distribution">Continuous Uniform Distribution</h3><p>Let $a, b \in \mathbb{R}$. We say that a continuous random variable $X$ follows a uniform distribution, denoted $U(a,b)$, if its p.d.f. $f$ is given by:</p>\[f(x) = \begin{cases} \dfrac{1}{b-a}, &amp; \text{for } a \le x \le b \\[2ex] 0, &amp; \text{for } x &lt; a \text{ or } x &gt; b \end{cases}\] \[E[X] = \dfrac{1}{2}(a+b)\] \[Var[X] = \dfrac{1}{12}(b-a)^2\]<p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Uniform_Distribution_PDF_SVG.svg/1200px-Uniform_Distribution_PDF_SVG.svg.png" alt="Continuous-Uniform-Distribution-img" width="500" /> <em>Continuous Uniform Distribution <a href="#references">[4]</a></em></p><h3 id="laplace-distribution">Laplace Distribution</h3><p>Let $\mu \in \mathbb{R} \text{ and } b &gt; 0$. We say that a continuous random variable $X$ follows a Laplace distribution, denoted $L(\mu, b)$, if its p.d.f. $f$ is given by:</p>\[f(x) = \dfrac{1}{2b} exp(-\dfrac{|x - \mu|}{b})= \dfrac{1}{2b} \begin{cases} exp(-\dfrac{\mu - x}{b}), &amp; \text{for } x &lt; \mu \\[2ex] exp(-\dfrac{x - \mu}{b}), &amp; \text{for } x \ge \mu \end{cases}\] \[E[X] = \mu\] \[Var[X] = 2b^2\]<p>where $\mu$ is a location parameter and $b$ is a scale parameter.</p><p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Laplace_pdf_mod.svg/325px-Laplace_pdf_mod.svg.png" alt="Laplace-Distribution-img" /> <em>Laplace Distribution <a href="#references">[5]</a></em></p><h2 id="references">References</h2><p>[1] <a href="https://towardsdatascience.com/understanding-the-68-95-99-7-rule-for-a-normal-distribution-b7b7cbf760c2">Explaining the 68-95-99.7 rule for a Normal Distribution</a></p><p>[2] <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal Distribution - Wikipedia</a></p><p>[3] <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential Distribution - Wikipedia</a></p><p>[4] <a href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution">Continuous Uniform Distribution - Wikipedia</a></p><p>[5] <a href="https://en.wikipedia.org/wiki/Laplace_distribution">Laplace Distribution - Wikipedia</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/blog/categories/tutorial/'>Tutorial</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/blog/tags/statistics/" class="post-tag no-text-decoration" >statistics</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Intro to Probability Theory - Asif Mammadov&url=https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Intro to Probability Theory - Asif Mammadov&u=https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Intro to Probability Theory - Asif Mammadov&url=https://sigrid30.github.io/blog/posts/Intro-to-Probability-Theory/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/blog/posts/Intro-to-Probability-Theory/">Intro to Probability Theory</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/blog/tags/statistics/">statistics</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div class="post-navigation d-flex justify-content-between"> <span class="btn btn-outline-primary disabled" prompt="Older"><p>-</p></span> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/asif_mammad">Asif Mammadov</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/blog/tags/statistics/">statistics</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/blog/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/blog/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/blog/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
